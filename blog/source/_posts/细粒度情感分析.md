---
title: 细粒度情感分析
date: 2019-08-27 16:45:37
tags: [细粒度情感分析]
---
# 细粒度情感分析
### 资料
[博客一](https://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&amp;mid=2650410618&amp;idx=1&amp;sn=610855fd9310ef593352503213305d2f&amp;chksm=becd882089ba013684817639d231e8df3b80dce196ca40878b6ce8432b0bd6dd0a7e04b82635&amp;scene=21#wechat_redirect)
[博客二](https://mp.weixin.qq.com/s/g7rAx-A7aSCRpemVV6hRkQ)

### Sentiment Analysis 按粒度可分为3种：
+ Document Level
+ Sentence Level
+ Aspect Level
<!-- more -->
> 其中, Aspect Level 的 Sentiment Analysis 按 Aspect 类型又可分为2种：

1. ATSA: Aspect-Term Sentiment Analysis

> Aspect-Term：不固定，不唯一，有很多Term共同表示同一种 Aspect，如 image,photo,picture 都是 Term 相关任务是 To group the same aspect expressions into a category，如上面三者可都归为 Image 这一 category

2. ACSA: Aspect-Category Sentiment Analysis

> Aspect-Category：表示一种 Aspect，固定而唯一，如上例中的 Image


### 以下模型都在公开数据集semeval2014上进行了实验(没有很仔细的调参)
### 历年模型

#### LSTM
1. 最简单的就是Sentence Level，经过enmbedding后接LSTM，最后一层接softmax多分类，模型如下
{% asset_img lstm.png lstm %}

**复现结果**

数据集 | acc | f1
-----|------|----
restaurant | 0.7464 | 0.6051
laptop | 0.6489 | 0.5366


#### TD-LSTM
[Effective LSTMs for Target-Dependent Sentiment Classification](https://arxiv.org/pdf/1512.01100.pdf)
1. 该方法就是以aspect词为分界点，将一句话分成左侧和右侧两个子句（包含aspect词），分别经过LSTM，最后cat起来，接softmax多分类

{% asset_img td_lstm.png td_lstm %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7545| 0.6012
laptop | 0.6254 | 0.5263

#### ATAE-LSTM
[Attention-based lstm for aspect-level sentiment classification](https://www.aclweb.org/anthology/D16-1058)
1. 该方法就是将aspect和sentences分别embedding后在输入端cat起来，然后输入到lstm得到hidden，在将hidden和aspect在做一次cat，输入给attention得到score权重，score和hidden做一次权重计算，接dense层得到分类结果，模型如图：

{% asset_img atae_lstm.jpg atae_lstm  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7652| 0.6322
laptop | 0.6693 | 0.5980


#### IAN 交互式注意力网络
[Interactive Attention Networks for Aspect-Level Sentiment Classification](https://arxiv.org/pdf/1709.00893.pdf)
1. 该模型的设计亮点在于sentence和aspect分别embedding后输入到lstm模型，得到的输出在dim=1维度求sum进行pool，然后分别交互做attention，最后cat起来接softmax分类，模型如下
{% asset_img ian.png ian  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7661| 0.6041
laptop | 0.7100 | 0.6451


#### MemNet
[Aspect Level Sentiment Classification with Deep Memory Network](https://arxiv.org/pdf/1605.08900.pdf)
1. 该模型将sentence中的aspect去除，分别将去除aspect的sentence和aspect进行embedding，然后多次循环分别计算attention，每次都与aspect进行cat，最后接一层全连接，模型如图：

{% asset_img memnet.png memnet  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7732| 0.6440
 laptop | 0.6928 | 0.6274


#### RAM
[Recurrent Attention Network on Memory for Aspect Sentiment Analysis](https://www.aclweb.org/anthology/D17-1047)
1. 该模型是和memnet对比的，很显然的一个想法就是memnet只是embdedding后计算attention，ram就是多加了一层lstm外加一个location位置信息，模型如下：

{% asset_img ram.png ram  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7839| 0.6572
 laptop | 0.7038 |0.6641


#### Cabasc
[Content Attention Model for Aspect Based Sentiment Analysis](http://delivery.acm.org/10.1145/3190000/3186001/p1023-liu.pdf?ip=47.75.80.8&id=3186001&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1565531666_72f1531e10628507b4901048107b6b09)
1. 该模型分别将sentence和aspect进行embedding，然后都在dim=1进行sum，求一个location位置信息得到sentence的三维矩阵A = [batchsize，seqlen，embedding]，将A在dim=1进行split分别与sentence和aspect在dim=1做了sum的矩阵cat，接两层dence，最后接softmax得到分类结果。模型如下：

{% asset_img cabasc.png cabasc  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7902| 0.6759
laptop | 0.7147 |0.6612


#### TNet
[Transformation Networks for Target-Oriented Sentiment Classification](https://arxiv.org/pdf/1805.01086.pdf)
1. 该模型引入了1维卷积，整个模型自下而上也是embedding、lstm、CNN，最后接softmax得到分类结果

{% asset_img tnet.png tnet  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7696| 0.6115
laptop | 0.6803 |0.6010


#### AOA
[Aspect Level Sentiment Classification with Attention-over-Attention Neural Networks](https://arxiv.org/pdf/1804.06536.pdf)
1. 该模型思想也挺简单的，也是分别将sentence和aspect经过embedding和lstm得到三维的矩阵A(batch size,sentenceslen, embedding)和B(batch size, aspectlen,embedding),然后计算一个torch.bmm(A,B.transpose(1,2)) 得到C(batchsize, sentencelen,aspectlen),分别在dim=1，2上计算C的softmax，将求过softmax的两个矩阵进行计算得到gamma矩阵，最后将gamma矩阵和A计算，接最后全连接层得到结果，模型如下：

{% asset_img aoa.png aoa  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7821| 0.6615
laptop | 0.6803 |0.6034


#### MGAN
[Multi-grained Attention Network for Aspect-Level Sentiment Classification](https://aclweb.org/anthology/D18-1380)
1. 该模型整体思路也比较简单，总的来看也是分别sentence和aspect进行embedding和lstm，分别池化，sentence和aspect进行交互，最后将得到的多个层面进行cat接全连接得到结果，模型如下：

{% asset_img mgan.png mgan  %}

数据集 | acc | f1
-----|------|----
restaurant | 0.7714| 0.6194
laptop | 0.6850 |0.6138


#### BERT for Sentence Pair Classification
[Bert: Pre-training of deep bidirectional transformers for language understanding](https://arxiv.org/pdf/1810.04805.pdf)

1. 该篇其实就是将bert的fine-tune进行了介绍，构造句子对的形式，输入给bert得到pool后的矩阵，接全连接层得到分类结果

{% asset_img bert.png bert  %}

数据集 | acc | f1
-----|------|----
restaurant |0.8214| 0.7186
laptop | 0.7492 |0.6765


#### AEN-BERT
[Attentional Encoder Network for Targeted Sentiment Classification](https://arxiv.org/pdf/1902.09314.pdf)

1. 该方法也是常规的操作，sentence和aspect都经过bert得到没有池化的三维矩阵，然后content和content自己做attention交互，content和target做attention交互，将两者做了attention交互后的矩阵在做一次attention交互，最后将三者cat起来，接输出层得到结果，模型如下：

{% asset_img aen.png aen  %}

数据集 | acc | f1
-----|------|----
restaurant |0.8313| 0.7426
laptop | 0.7508 |0.6879
